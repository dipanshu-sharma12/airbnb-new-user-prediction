{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "-h0aIAybOAp0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import os\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import re\n",
        "import nltk\n",
        "from wordcloud import WordCloud\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datetime import datetime, date\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import coo_matrix\n",
        "from scipy.sparse import hstack\n",
        "from scipy.sparse import vstack\n",
        "from scipy import sparse\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.preprocessing import LabelBinarizer,LabelEncoder\n",
        "from scipy.stats import randint as sp_randint\n",
        "from sklearn import linear_model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "import pickle\n",
        "import joblib\n",
        "from IPython.display import Image\n",
        "# tokenisation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6lxedoSoJR9",
        "outputId": "8d56cb93-3c6d-40a7-ddbd-57b2f90c3e92"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.kaggle.com/davidgasquez/ndcg-scorer\n",
        "\n",
        "def dcg_score(y_true, y_score, k=5):\n",
        "    \n",
        "    \n",
        "    order = np.argsort(y_score)[::-1]\n",
        "    y_true = np.take(y_true, order[:k])\n",
        "\n",
        "    gain = 2 ** y_true - 1\n",
        "\n",
        "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
        "    return np.sum(gain / discounts)\n",
        "\n",
        "\n",
        "def ndcg_score(ground_truth, predictions, k=5):\n",
        "    \n",
        "    \n",
        "    lb = LabelBinarizer()\n",
        "    lb.fit(range(predictions.shape[1] + 1))\n",
        "    T = lb.transform(ground_truth)\n",
        "\n",
        "    scores = []\n",
        "\n",
        "    # Iterate over each y_true and compute the DCG score\n",
        "    for y_true, y_score in zip(T, predictions):\n",
        "        actual = dcg_score(y_true, y_score, k)\n",
        "        best = dcg_score(y_true, y_true, k)\n",
        "        score = float(actual) / float(best)\n",
        "        scores.append(score)\n",
        "\n",
        "    return np.mean(scores)\n",
        "\n",
        "\n",
        "# NDCG Scorer function\n",
        "ndcg_scorer = make_scorer(ndcg_score, needs_proba=True, k=5)\n"
      ],
      "metadata": {
        "id": "qU4ZPT06O45n"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def age_mode(age):        #function to replace outliers with mode\n",
        "    \n",
        "    \n",
        "  if age < 18.0 or age > 100.0: \n",
        "        \n",
        "        return 29.0\n",
        "  \n",
        "  else: \n",
        "        \n",
        "        return age\n"
      ],
      "metadata": {
        "id": "KPv_fwuWPDHo"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading from memory\n",
        "y = np.load('/content/drive/MyDrive/y.npy',allow_pickle=True)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/col_lst.txt\", \"rb\") as fp:\n",
        "    \n",
        "   col_lst = pickle.load(fp)\n",
        "    \n",
        "fp.close()\n",
        "\n",
        "with open(\"/content/drive/MyDrive/lst_ohe_train.txt\", \"rb\") as fp:\n",
        "    \n",
        "    lst_ohe_train = pickle.load(fp)\n",
        "    \n",
        "fp.close()\n",
        "\n",
        "vectorizer_action = pickle.load(open('/content/drive/MyDrive/vectorizer_action.pickle', 'rb'))\n",
        "\n",
        "vectorizer_action_type = pickle.load(open(\"/content/drive/MyDrive/vectorizer_action_type.pickle\", \"rb\"))\n",
        "\n",
        "vectorizer_action_detail = pickle.load(open(\"/content/drive/MyDrive/vectorizer_action_detail.pickle\", \"rb\"))\n",
        "\n",
        "\n",
        "session_df_concat = pd.read_pickle('/content/drive/MyDrive/session_df_concat.pickle')\n",
        "\n",
        "train = pd.read_pickle('/content/drive/MyDrive/train_raw.pickle')\n",
        "\n",
        "\n",
        "clf = joblib.load('/content/drive/MyDrive/xgb')  # Our pretrained Xgboost Model"
      ],
      "metadata": {
        "id": "WFI_MUScPOWG"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "# Encoding country \n",
        "y = le.fit_transform(y)\n",
        "\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOR_DrlYwFlR",
        "outputId": "a0bc7fb9-7be9-4e0b-d854-349fedd5545f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([11,  7,  7, ...,  7,  7,  7])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lst_ohe = ['gender', 'signup_method', 'language', 'affiliate_channel',\\\n",
        "            'affiliate_provider', 'signup_app',  'first_browser']\n",
        "\n",
        "raw_df = train[:2]             #Checking for first 2 rows from training data\n",
        "\n",
        "raw_label = y[:2]              #Taking corresponding y values\n",
        "raw_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cOXO73GPZ4z",
        "outputId": "90a3bab2-d37a-4aff-9a70-6d98ce02a669"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['user_id', 'gender', 'age', 'signup_method', 'signup_flow', 'language',\n",
              "       'affiliate_channel', 'affiliate_provider', 'signup_app',\n",
              "       'first_device_type', 'first_browser', 'country_destination', 'action',\n",
              "       'action_type', 'action_detail', 'secs_elapsed', 'account_created_day',\n",
              "       'account_created_month', 'first_booking_day', 'first_booking_month'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9mptDcJDiKD",
        "outputId": "a713e501-2781-4940-9e5f-105bae98418b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['user_id', 'gender', 'age', 'signup_method', 'signup_flow', 'language',\n",
              "       'affiliate_channel', 'affiliate_provider', 'signup_app',\n",
              "       'first_device_type', 'first_browser', 'country_destination', 'action',\n",
              "       'action_type', 'action_detail', 'secs_elapsed', 'account_created_day',\n",
              "       'account_created_month', 'first_booking_day', 'first_booking_month'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def f1(train):    # This function takes X i.e raw data and performs encoding of data and gets prediction of data from pretrained model\n",
        "\n",
        " X= train.drop(['country_destination'], axis=1)\n",
        " data_action_tfidf = vectorizer_action.transform(X['action'].values)\n",
        " data_action_type_tfidf = vectorizer_action_type.transform(X['action_type'].values)\n",
        " data_action_detail_tfidf = vectorizer_action_detail.transform(X['action_detail'].values)\n",
        " X= train.drop(['country_destination'], axis=1)\n",
        " countries = []\n",
        " X['user_id'].fillna('na' , inplace=True)\n",
        " X['action'].fillna('na' , inplace=True)\n",
        " X['action_type'].fillna('na' , inplace=True)\n",
        " X['action_detail'].fillna('na' , inplace=True)\n",
        " X['first_device_type'].fillna('na' , inplace=True)\n",
        " X['secs_elapsed'].fillna(0, inplace=True)\n",
        " X['age'] = X['age'].apply(age_mode)\n",
        " X['age'].fillna(29.0 , inplace=True)\n",
        " X.drop(['user_id'],axis=1,inplace = True)\n",
        "    \n",
        " for i in range(len(lst_ohe)):\n",
        "        \n",
        "        ohe = pd.get_dummies(X[lst_ohe[i]], prefix=lst_ohe[i])\n",
        "        \n",
        "        X.drop([lst_ohe[i]], axis=1, inplace = True)\n",
        "        \n",
        "        # Get missing columns in the training test\n",
        "    \n",
        "        missing_cols = set( lst_ohe_train[i] ) - set( ohe.columns )\n",
        "    \n",
        "        # Add a missing column in test set with default value equal to 0\n",
        "    \n",
        "        for c in missing_cols:\n",
        "            \n",
        "            ohe[c] = 0\n",
        "        \n",
        "        #To make sur that order of column in the test set is in the same order than in train set\n",
        "    \n",
        "        ohe = ohe[lst_ohe_train[i]]\n",
        "    \n",
        "        data = pd.concat((X, ohe), axis=1)\n",
        "        \n",
        " #ohe = X['first_device_type'].str.get_dummies(sep=\",\")\n",
        "    \n",
        " #X.drop(['first_device_type'], axis=1, inplace = True)\n",
        "    \n",
        "    # Get missing columns in the training test\n",
        "    \n",
        " missing_cols = set( lst_ohe_train[-1] ) - set( ohe.columns )\n",
        "    \n",
        "    # Add a missing column in test set with default value equal to 0\n",
        "    \n",
        " for c in missing_cols:\n",
        "        \n",
        "      ohe[c] = 0\n",
        "        \n",
        "    # Ensure the order of column in the test set is in the same order than in train set\n",
        "    \n",
        "      ohe = ohe[lst_ohe_train[-1]]\n",
        "    \n",
        "      X = pd.concat((data, ohe), axis=1)    \n",
        "    \n",
        " data_action_tfidf = vectorizer_action.transform(X['action'].values)\n",
        "    \n",
        " data_action_type_tfidf = vectorizer_action_type.transform(X['action_type'].values)\n",
        "        \n",
        " data_action_detail_tfidf = vectorizer_action_detail.transform(X['action_detail'].values)\n",
        "        \n",
        " X.drop(['action','action_type','action_detail'],axis=1,inplace = True)\n",
        "    \n",
        " data_tfidf = hstack((X,data_action_tfidf,data_action_type_tfidf,data_action_detail_tfidf)).tocsr()\n",
        "\n",
        "\n",
        "\n",
        " from xgboost import XGBClassifier\n",
        " pred = xgb.predict_proba(data_tfidf)   \n",
        " for i in pred:\n",
        "        \n",
        "        countries.append(le.inverse_transform(np.argsort(i)[::-1][:5]).tolist())\n",
        "    \n",
        " return countries,pred\n"
      ],
      "metadata": {
        "id": "LBjpt_pm4qCI"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# func2 to output score depending on prediction and actual value\n",
        "\n",
        "def func2(label,pred):\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    Function takes label and pred as input and returns ndcg score.\n",
        "    \n",
        "    parameters:  label , pred\n",
        "        \n",
        "    \"\"\"\n",
        "    \n",
        "    score = ndcg_score(label,pred,5)\n",
        "    \n",
        "    return score\n"
      ],
      "metadata": {
        "id": "jgyMhOxOJx4G"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "country,pred = f1(train[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_FHeP18JgFe",
        "outputId": "1cd50123-c4f6-4af0-a352-abca26a27619"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['US', 'NDF', 'other', 'GB', 'IT'], ['NDF', 'US', 'other', 'FR', 'GB']] [[ 0.07227261  0.07268214  0.07244734  0.0727839   0.0736526   0.07426566\n",
            "   0.07396927  0.11341434  0.07238723  0.07212908  0.12122008  0.10877571]\n",
            " [ 0.06988983  0.07025965  0.07004832  0.0703583   0.0706948   0.07053546\n",
            "   0.07049852  0.2142804   0.07002889  0.06979483  0.08207586  0.07153518]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = func2(y,pred)\n",
        "\n",
        "score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJgzI6tZilQn",
        "outputId": "7e8db314-e018-4376-babd-82ef3597b876"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.75\n"
          ]
        }
      ]
    }
  ]
}